{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDL_Homework_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fc2a5d53c236465d9998ce568c9b0924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32b5128d7d804fc4ab663d7a0a392a49",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_104f249911c643b3977a91cccc4eef65",
              "IPY_MODEL_e4be88d8d6884426b98a3cf48b9b4084"
            ]
          }
        },
        "32b5128d7d804fc4ab663d7a0a392a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "104f249911c643b3977a91cccc4eef65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bd7bf3e36c6b4190a56432948c04437b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244418560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244418560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1dd3cf5c7d7945188204873d179ddf26"
          }
        },
        "e4be88d8d6884426b98a3cf48b9b4084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9186ad1acdcc48dca7d808a58b3dc065",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [09:37&lt;00:00, 423kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09b40f60737c45b1a5e109271334f355"
          }
        },
        "bd7bf3e36c6b4190a56432948c04437b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1dd3cf5c7d7945188204873d179ddf26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9186ad1acdcc48dca7d808a58b3dc065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09b40f60737c45b1a5e109271334f355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAoD2Yz09N1p",
        "colab_type": "text"
      },
      "source": [
        "**Politecnico di Torino**\n",
        "\n",
        "**01TXFSM - Machine learning and Deep learning**\n",
        "\n",
        "**Homework 3**\n",
        "\n",
        "**Alberto Maria Falletta - s277971**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QcGnGPdX2C",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9O3aM3Tb28q",
        "colab_type": "code",
        "outputId": "dad46cde-94a8-41ae-8573-dd76afac4a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "!pip3 install 'torch==1.4.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision==0.5.0 in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.4.0)\n",
            "Requirement already satisfied: Pillow-SIMD in /usr/local/lib/python3.6/dist-packages (7.0.0.post3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqR0NR8Fv03V",
        "colab_type": "text"
      },
      "source": [
        "**AlexNet with domain Adaptation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G90aVZibv0jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.hub import load_state_dict_from_url\n",
        "from torch.autograd import Function\n",
        "\n",
        "__all__ = ['AlexNet', 'alexnet']\n",
        "\n",
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "}\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "    # Forwards identity\n",
        "    # Sends backward reversed gradients\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "\n",
        "        return output, None\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, alpha):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        reverse_feature = ReverseLayerF.apply(x, alpha)\n",
        "        class_output = self.classifier(x)\n",
        "        domain_output = self.domain_classifier(reverse_feature)\n",
        "\n",
        "        # if alpha is None:\n",
        "        #     x = self.classifier(x)\n",
        "        # else:\n",
        "        #     x = ReverseLayerF.apply(x, alpha)\n",
        "        #     x = self.domain_classifier(x)\n",
        "\n",
        "        # return x\n",
        "        return class_output, domain_output\n",
        "\n",
        "\n",
        "def alexnet_with_dann(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'], progress=progress)\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "        # Copying pretrained weights and biases to the new branch\n",
        "        model.domain_classifier[1].weight.data = model.classifier[1].weight.data\n",
        "        model.domain_classifier[1].bias.data = model.classifier[1].bias.data\n",
        "        model.domain_classifier[4].weight.data = model.classifier[4].weight.data\n",
        "        model.domain_classifier[4].bias.data = model.classifier[4].bias.data\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTouQjVKxcx8",
        "colab_type": "text"
      },
      "source": [
        "**Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwlaH5hUxbB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_key(in_dict, in_value):\n",
        "  \"\"\"\n",
        "  This function accepts an integer value and returns\n",
        "  the string associated to the class name relating \n",
        "  to the integer, using the class_to_idx dictionary.\n",
        "  \"\"\"\n",
        "\n",
        "  for key, value in in_dict.items():\n",
        "    if in_value == value: \n",
        "      return key \n",
        "  return \"Key not found!\"\n",
        "\n",
        "\n",
        "def print_occurrences(in_dataset, filename, save=False):\n",
        "  \"\"\"\n",
        "  This function prints horizontal bar-graphs\n",
        "  of occurrences of dataset's images.\n",
        "  Uses get_key to decode the class name\n",
        "  from its integer value.\n",
        "  \"\"\"\n",
        "\n",
        "  in_occurrence_dict = {}\n",
        "  # in_dataset is an object of Pacs class, therefore using .sample \n",
        "  # a list of images and labels is return.\n",
        "  # These lines build a dictionary from in_dataset with labels as key and number\n",
        "  # of occurrences as value\n",
        "  for index in range(0, len(in_dataset)):\n",
        "    img_data, img_label = in_dataset.samples[index]\n",
        "    if img_label not in in_occurrence_dict:\n",
        "      in_occurrence_dict[img_label] = 1\n",
        "    else:\n",
        "      in_occurrence_dict[img_label] += 1\n",
        "\n",
        "  in_y = []\n",
        "  in_x = []\n",
        "\n",
        "  for key in in_occurrence_dict:\n",
        "    in_y.append(get_key(in_dataset.class_to_idx, key))\n",
        "    in_x.append(in_occurrence_dict[key])\n",
        "\n",
        "  # Plot\n",
        "  fig, ax = plt.subplots(figsize=(9, 5))\n",
        "  ax.barh(in_y, in_x, align='center', alpha=0.5)\n",
        "  ax.set_xlabel('Number of images')\n",
        "  ax.set_ylabel('Classes')\n",
        "  ax.set_title(filename)\n",
        "  for i, v in enumerate(in_x):\n",
        "    plt.text(v+0.2, i, str(v), color='steelblue', va=\"center\")\n",
        "  if save:\n",
        "    plt.savefig(filename + '.png')\n",
        "  plt.show()\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "def print_accuracy_loss_plot(in_loss_list, in_accuracy_list, filename):\n",
        "  \"\"\"\n",
        "  This function prints line plots for test accuracy and loss\n",
        "  for each epoch\n",
        "  \"\"\"\n",
        "  in_epochs = [*range(0, len(in_loss_list))]\n",
        "  in_fig, in_ax = plt.subplots(1, 2, figsize=(14, 7))\n",
        "  in_ax[0].plot(in_epochs, in_loss_list, c='blue', label='Loss')\n",
        "  in_ax[1].plot(in_epochs, in_accuracy_list, c='green', label='Test Accuracy')\n",
        "  in_ax[0].set_xlabel('Epochs')\n",
        "  in_ax[1].set_xlabel('Epochs')\n",
        "  in_ax[0].set_ylabel('Loss')\n",
        "  in_ax[1].set_ylabel('Test Accuracy')\n",
        "  plt.savefig(filename + '.png')\n",
        "  plt.show()\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "NUM_CLASSES = 7\n",
        "\n",
        "BATCH_SIZE = 128     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 1e-3            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 35      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 30       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
        "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
        "])\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                                 \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI5LFLAAyXvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In case of need\n",
        "if os.path.isdir('./PACS'):\n",
        "  !rm -rf PACS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./PACS'):\n",
        "  !git clone https://github.com/albeffe/Homework3-PACS\n",
        "  !mv 'Homework3-PACS' 'PACS'\n",
        "\n",
        "DATA_DIR = 'PACS/PACS'\n",
        "from my_folder.my_pacs_dataset import Pacs\n",
        "\n",
        "# Prepare Pytorch train/test Datasets\n",
        "art_dataset = Pacs(os.path.join(DATA_DIR, \"art_painting\"), transform=train_transform)\n",
        "cartoon_dataset = Pacs(os.path.join(DATA_DIR, \"cartoon\"), transform=train_transform)\n",
        "photo_dataset = Pacs(os.path.join(DATA_DIR, \"photo\"), transform=train_transform)\n",
        "sketch_dataset = Pacs(os.path.join(DATA_DIR, \"sketch\"), transform=train_transform)\n",
        "\n",
        "# For visualization purposes\n",
        "visualization_flag = False\n",
        "if visualization_flag:\n",
        "  print('Art Painting Dataset Items: {}'.format(len(art_dataset)))\n",
        "  print('Cartoon Dataset Items: {}'.format(len(cartoon_dataset)))\n",
        "  print('Photo Dataset Items: {}'.format(len(photo_dataset)))\n",
        "  print('Sketch Dataset Items: {}'.format(len(sketch_dataset)))\n",
        "\n",
        "  print_occurrences(art_dataset, 'Art Painting Dataset', True)\n",
        "  print_occurrences(cartoon_dataset, 'Cartoon Dataset', True)\n",
        "  print_occurrences(photo_dataset, 'Photo Dataset', True)\n",
        "  print_occurrences(sketch_dataset, 'Sketch Dataset', True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training\n",
        "source_dataloader = DataLoader(photo_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "target_dataloader = DataLoader(art_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "# Evaluation\n",
        "test_dataloader = DataLoader(art_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "fc2a5d53c236465d9998ce568c9b0924",
            "32b5128d7d804fc4ab663d7a0a392a49",
            "104f249911c643b3977a91cccc4eef65",
            "e4be88d8d6884426b98a3cf48b9b4084",
            "bd7bf3e36c6b4190a56432948c04437b",
            "1dd3cf5c7d7945188204873d179ddf26",
            "9186ad1acdcc48dca7d808a58b3dc065",
            "09b40f60737c45b1a5e109271334f355"
          ]
        },
        "outputId": "59f9e5d7-b2a3-4774-b7fb-1e8c07fea795"
      },
      "source": [
        "net = alexnet(pretrained=True)\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc2a5d53c236465d9998ce568c9b0924",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "**Train without DANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "outputId": "42973b25-34b5-46af-ca88-e3439f2d2b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "net = net.to(DEVICE)\n",
        "\n",
        "cudnn.benchmark \n",
        "\n",
        "current_step = 0\n",
        "loss_list = []\n",
        "test_accuracy_list = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "\n",
        "  # Iterate over the dataset\n",
        "  for images, labels in source_dataloader:\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train() # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Compute loss based on output and ground truth\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "  # Step the scheduler\n",
        "  scheduler.step() \n",
        "\n",
        "  loss_list.append(loss.item())\n",
        "\n",
        "  # Test \n",
        "  net.train(False) # Set Network to evaluation mode\n",
        "  test_running_corrects = 0\n",
        "  for images, labels in test_dataloader:\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    test_outputs = net(images)\n",
        "\n",
        "    # Get predictions\n",
        "    _, test_preds = torch.max(test_outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    test_running_corrects += torch.sum(test_preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  test_accuracy = test_running_corrects / float(len(art_dataset))\n",
        "  print('Test Accuracy {}'.format(test_accuracy))\n",
        "  print()\n",
        "  \n",
        "  test_accuracy_list.append(test_accuracy)\n",
        "\n",
        "print_accuracy_loss_plot(loss_list, test_accuracy_list, \"Training without DANN\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/30, LR = [0.001]\n",
            "Step 0, Loss 2.349184274673462\n",
            "Test Accuracy 0.37255859375\n",
            "\n",
            "Starting epoch 2/30, LR = [0.001]\n",
            "Step 10, Loss 0.31603628396987915\n",
            "Test Accuracy 0.44580078125\n",
            "\n",
            "Starting epoch 3/30, LR = [0.001]\n",
            "Test Accuracy 0.43310546875\n",
            "\n",
            "Starting epoch 4/30, LR = [0.001]\n",
            "Step 20, Loss 0.14002126455307007\n",
            "Test Accuracy 0.4375\n",
            "\n",
            "Starting epoch 5/30, LR = [0.001]\n",
            "Test Accuracy 0.4404296875\n",
            "\n",
            "Starting epoch 6/30, LR = [0.001]\n",
            "Step 30, Loss 0.13388288021087646\n",
            "Test Accuracy 0.455078125\n",
            "\n",
            "Starting epoch 7/30, LR = [0.001]\n",
            "Step 40, Loss 0.052623867988586426\n",
            "Test Accuracy 0.46435546875\n",
            "\n",
            "Starting epoch 8/30, LR = [0.001]\n",
            "Test Accuracy 0.46435546875\n",
            "\n",
            "Starting epoch 9/30, LR = [0.001]\n",
            "Step 50, Loss 0.05879181623458862\n",
            "Test Accuracy 0.47119140625\n",
            "\n",
            "Starting epoch 10/30, LR = [0.001]\n",
            "Test Accuracy 0.48779296875\n",
            "\n",
            "Starting epoch 11/30, LR = [0.001]\n",
            "Step 60, Loss 0.03461284935474396\n",
            "Test Accuracy 0.48681640625\n",
            "\n",
            "Starting epoch 12/30, LR = [0.001]\n",
            "Step 70, Loss 0.04049750417470932\n",
            "Test Accuracy 0.48828125\n",
            "\n",
            "Starting epoch 13/30, LR = [0.001]\n",
            "Test Accuracy 0.4912109375\n",
            "\n",
            "Starting epoch 14/30, LR = [0.001]\n",
            "Step 80, Loss 0.03704206645488739\n",
            "Test Accuracy 0.490234375\n",
            "\n",
            "Starting epoch 15/30, LR = [0.001]\n",
            "Test Accuracy 0.48876953125\n",
            "\n",
            "Starting epoch 16/30, LR = [0.001]\n",
            "Step 90, Loss 0.02862362004816532\n",
            "Test Accuracy 0.49267578125\n",
            "\n",
            "Starting epoch 17/30, LR = [0.001]\n",
            "Step 100, Loss 0.030162334442138672\n",
            "Test Accuracy 0.48876953125\n",
            "\n",
            "Starting epoch 18/30, LR = [0.001]\n",
            "Test Accuracy 0.48193359375\n",
            "\n",
            "Starting epoch 19/30, LR = [0.001]\n",
            "Step 110, Loss 0.02288060635328293\n",
            "Test Accuracy 0.48779296875\n",
            "\n",
            "Starting epoch 20/30, LR = [0.001]\n",
            "Test Accuracy 0.4873046875\n",
            "\n",
            "Starting epoch 21/30, LR = [1e-05]\n",
            "Step 120, Loss 0.024584563449025154\n",
            "Test Accuracy 0.48828125\n",
            "\n",
            "Starting epoch 22/30, LR = [0.0001]\n",
            "Step 130, Loss 0.020692501217126846\n",
            "Test Accuracy 0.48779296875\n",
            "\n",
            "Starting epoch 23/30, LR = [0.0001]\n",
            "Test Accuracy 0.48876953125\n",
            "\n",
            "Starting epoch 24/30, LR = [0.0001]\n",
            "Step 140, Loss 0.011457959190011024\n",
            "Test Accuracy 0.4892578125\n",
            "\n",
            "Starting epoch 25/30, LR = [0.0001]\n",
            "Test Accuracy 0.48828125\n",
            "\n",
            "Starting epoch 26/30, LR = [0.0001]\n",
            "Step 150, Loss 0.015063845552504063\n",
            "Test Accuracy 0.4873046875\n",
            "\n",
            "Starting epoch 27/30, LR = [0.0001]\n",
            "Step 160, Loss 0.016206877306103706\n",
            "Test Accuracy 0.48828125\n",
            "\n",
            "Starting epoch 28/30, LR = [0.0001]\n",
            "Test Accuracy 0.48828125\n",
            "\n",
            "Starting epoch 29/30, LR = [0.0001]\n",
            "Step 170, Loss 0.027748752385377884\n",
            "Test Accuracy 0.48779296875\n",
            "\n",
            "Starting epoch 30/30, LR = [0.0001]\n",
            "Test Accuracy 0.4873046875\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSJYX1aWE7Yl",
        "colab_type": "text"
      },
      "source": [
        "**Test without DANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzJQJrZmE-mc",
        "colab_type": "code",
        "outputId": "43de72d5-6745-46df-ab4b-226b402eab43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "net = net.to(DEVICE)\n",
        "net.train(False)\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(test_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(art_dataset))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.4873046875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz-eTG2Z9_zG",
        "colab_type": "text"
      },
      "source": [
        "**Training with DANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWR1N5yf32JM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = alexnet_with_dann(pretrained=True)\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc_auE9KwgqP",
        "colab_type": "code",
        "outputId": "731699f9-bb88-411c-fc76-04bff8ceb99f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "net = net.to(DEVICE)\n",
        "cudnn.benchmark\n",
        "\n",
        "current_step = 0\n",
        "loss_list = []\n",
        "test_accuracy_list = []\n",
        "\n",
        "# Static adaptation factor\n",
        "alpha = 0.2\n",
        "\n",
        "# Start iterating over the epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "\n",
        "  # Iterate over the dataset\n",
        "  train_running_corrects = 0\n",
        "\n",
        "  len_dataloader = min(len(source_dataloader), len(target_dataloader))\n",
        "  data_source_iter = iter(source_dataloader)\n",
        "  data_target_iter = iter(target_dataloader)\n",
        "  i = 0\n",
        "\n",
        "  while i < len_dataloader:\n",
        "\n",
        "    # Dynamic adaptation factor # 1\n",
        "    p = float(epoch) / NUM_EPOCHS / len_dataloader\n",
        "    alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "\n",
        "    # Dynamic adaptation factor # 2\n",
        "    # alpha = (1/NUM_EPOCHS) * (epoch)\n",
        "\n",
        "    # Dynamic adaptation factor # 3\n",
        "    # alpha = (1/NUM_EPOCHS) * (epoch)\n",
        "    # if alpha > 0.5:\n",
        "    #  alpha = 0.5\n",
        "\n",
        "\n",
        "\n",
        "    # Training on source data\n",
        "    data_source = data_source_iter.next()\n",
        "\n",
        "    images = data_source[0].to(DEVICE)\n",
        "    class_label = data_source[1].to(DEVICE)\n",
        "    domain_label = torch.zeros(BATCH_SIZE, dtype=torch.long).to(DEVICE)\n",
        "\n",
        "    net.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    class_output, domain_output = net(images, alpha)\n",
        "    loss_s_label = criterion(class_output, class_label)\n",
        "    loss_s_domain = criterion(domain_output, domain_label)\n",
        "    \n",
        "    # Training on target data\n",
        "    data_target = data_target_iter.next()\n",
        "    \n",
        "    images = data_target[0].to(DEVICE)\n",
        "    domain_label = torch.ones(BATCH_SIZE, dtype=torch.long).to(DEVICE)\n",
        "\n",
        "    _, domain_output = net(images, alpha)\n",
        "    loss_t_domain = criterion(domain_output, domain_label)\n",
        "    loss = loss_t_domain + loss_s_domain + loss_s_label\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    i += 1\n",
        "\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}, Alpha {}'.format(current_step, loss.item(), alpha))\n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "  # Step the scheduler\n",
        "  scheduler.step()\n",
        "\n",
        "  loss_list.append(loss_s_label.item())\n",
        "\n",
        "  # Test \n",
        "  net.train(False)\n",
        "  test_running_corrects = 0\n",
        "  for images, labels in test_dataloader:\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    test_outputs, _ = net(images, alpha)\n",
        "\n",
        "    # Get predictions\n",
        "    _, test_preds = torch.max(test_outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    test_running_corrects += torch.sum(test_preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  test_accuracy = test_running_corrects / float(len(art_dataset))\n",
        "  print('Test Accuracy {}'.format(test_accuracy))\n",
        "  print()\n",
        "\n",
        "  test_accuracy_list.append(test_accuracy)\n",
        "\n",
        "print_accuracy_loss_plot(loss_list, test_accuracy_list, \"Training with DANN\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/35, LR = [0.001]\n",
            "Step 0, Loss 3.5017642974853516, Alpha 0.0\n",
            "Step 10, Loss 0.769342303276062, Alpha 0.0\n",
            "Test Accuracy 0.49462890625\n",
            "\n",
            "Starting epoch 2/35, LR = [0.001]\n",
            "Step 20, Loss 0.44245582818984985, Alpha 0.010988568672052113\n",
            "Test Accuracy 0.47509765625\n",
            "\n",
            "Starting epoch 3/35, LR = [0.001]\n",
            "Step 30, Loss 0.2517087459564209, Alpha 0.021974483955019997\n",
            "Test Accuracy 0.4873046875\n",
            "\n",
            "Starting epoch 4/35, LR = [0.001]\n",
            "Step 40, Loss 0.18618939816951752, Alpha 0.03295509502203586\n",
            "Step 50, Loss 0.3047999143600464, Alpha 0.03295509502203586\n",
            "Test Accuracy 0.4990234375\n",
            "\n",
            "Starting epoch 5/35, LR = [0.001]\n",
            "Step 60, Loss 0.1682405173778534, Alpha 0.04392775616541034\n",
            "Test Accuracy 0.50439453125\n",
            "\n",
            "Starting epoch 6/35, LR = [0.001]\n",
            "Step 70, Loss 0.24104471504688263, Alpha 0.05488982934309927\n",
            "Test Accuracy 0.49658203125\n",
            "\n",
            "Starting epoch 7/35, LR = [0.001]\n",
            "Step 80, Loss 0.19707730412483215, Alpha 0.06583868670947934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxekmR745ySe",
        "colab_type": "text"
      },
      "source": [
        "**Test with DANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSHcUqLB5yWO",
        "colab_type": "code",
        "outputId": "f2d157ac-7db6-4c0c-c3ac-c8c4300b576e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "net = net.to(DEVICE)\n",
        "net.train(False)\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(test_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs, _ = net(images, alpha)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(art_dataset))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.50830078125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm9M9IP9oDsV",
        "colab_type": "text"
      },
      "source": [
        "**GRID SEARCH Photo to Cartoon and Photo to Sketch without DANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CLbZd8JoP-L",
        "colab_type": "code",
        "outputId": "ecd383d9-2da6-465f-f4ac-5eb7e6e1a3f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hyp_parameters = {\n",
        "  \"batch_size\": [256, 512],\n",
        "  \"lr\": [0.01, 0.001],\n",
        "  \"step\": [20, 30],\n",
        "  \"num_epochs\": [40]\n",
        "  }\n",
        "\n",
        "max_valid_accuracy = 0\n",
        "avg_accuracy = 0\n",
        "best_config = {}\n",
        "number_of_configurations = 2 * 2 * 2\n",
        "current_config = 0\n",
        "\n",
        "for config in ParameterGrid(hyp_parameters):\n",
        "  \n",
        "  photo_dataloader = DataLoader(photo_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4, drop_last=True)\n",
        "  cartoon_dataloader = DataLoader(cartoon_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=4)\n",
        "  sketch_dataloader = DataLoader(sketch_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=4)\n",
        "\n",
        "  net = alexnet(pretrained=True)\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "  parameters_to_optimize = net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=config['lr'], momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config['step'], gamma=GAMMA)\n",
        "\n",
        "  net = net.to(DEVICE)\n",
        "  cudnn.benchmark \n",
        "\n",
        "  current_step = 0\n",
        "  nan_flag = False\n",
        "  current_config += 1\n",
        "\n",
        "  for epoch in range(config['num_epochs']):\n",
        "    print('Starting epoch {}/{}'.format(epoch+1, config['num_epochs']))\n",
        "\n",
        "    # Photo Training -----------------------------------------------------------\n",
        "    for images, labels in photo_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      net.train()\n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      if math.isnan(loss):\n",
        "        nan_flag = True\n",
        "\n",
        "      # if current_step % LOG_FREQUENCY == 0:\n",
        "        # print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      current_step += 1\n",
        "\n",
        "    if nan_flag:\n",
        "      print()\n",
        "      break\n",
        "\n",
        "    scheduler.step() \n",
        "\n",
        "    # Cartoon Validation -------------------------------------------------------\n",
        "    net.train(False)\n",
        "    cartoon_running_corrects = 0\n",
        "    for images, labels in cartoon_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      cartoon_outputs = net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, cartoon_preds = torch.max(cartoon_outputs.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      cartoon_running_corrects += torch.sum(cartoon_preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    cartoon_accuracy = cartoon_running_corrects / float(len(cartoon_dataset))\n",
        "\n",
        "    # Sketch Validation --------------------------------------------------------\n",
        "    net.train(False)\n",
        "    sketch_running_corrects = 0\n",
        "    for images, labels in sketch_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      sketch_outputs = net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, sketch_preds = torch.max(sketch_outputs.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      sketch_running_corrects += torch.sum(sketch_preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    sketch_accuracy = sketch_running_corrects / float(len(sketch_dataset))\n",
        "\n",
        "    # Best Configuration -------------------------------------------------------\n",
        "    avg_accuracy = (sketch_accuracy + cartoon_accuracy) / 2\n",
        "    if avg_accuracy > max_valid_accuracy:\n",
        "      max_valid_accuracy = avg_accuracy\n",
        "      best_config = config\n",
        "\n",
        "  print(avg_accuracy, config)\n",
        "\n",
        "print(f\"Max Accuracy = {max_valid_accuracy}\")\n",
        "print(f\"Achieved with configuration: {best_config}\")\n",
        "\n",
        "# Max Accuracy = 0.32892334022760655\n",
        "# Achieved with configuration: {'batch_size': 512, 'lr': 0.01, 'num_epochs': 35, 'step': 30}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.26125426403995144 {'batch_size': 256, 'lr': 0.01, 'num_epochs': 40, 'step': 20}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.3086406475173233 {'batch_size': 256, 'lr': 0.01, 'num_epochs': 40, 'step': 30}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.23596607487684557 {'batch_size': 256, 'lr': 0.001, 'num_epochs': 40, 'step': 20}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.24877556795231398 {'batch_size': 256, 'lr': 0.001, 'num_epochs': 40, 'step': 30}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.28132478628766405 {'batch_size': 512, 'lr': 0.01, 'num_epochs': 40, 'step': 20}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.3129141341577506 {'batch_size': 512, 'lr': 0.01, 'num_epochs': 40, 'step': 30}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.18553758609516877 {'batch_size': 512, 'lr': 0.001, 'num_epochs': 40, 'step': 20}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.23605940164889244 {'batch_size': 512, 'lr': 0.001, 'num_epochs': 40, 'step': 30}\n",
            "Max Accuracy = 0.3324611252461568\n",
            "Achieved with configuration: {'batch_size': 256, 'lr': 0.01, 'num_epochs': 40, 'step': 30}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0zV8QV-0R-C",
        "colab_type": "text"
      },
      "source": [
        "**3A with best config**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNlTnb9I0P1K",
        "colab_type": "code",
        "outputId": "a257aa7f-fa7a-4af9-e3d8-432bb1df4950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# To avoid re-run of previous code cell\n",
        "# Max Accuracy = 0.32892334022760655\n",
        "best_config = {'batch_size': 512, 'lr': 0.01, 'num_epochs': 35, 'step': 30}\n",
        "\n",
        "source_dataloader = DataLoader(photo_dataset, batch_size=best_config[\"batch_size\"], shuffle=True, num_workers=4, drop_last=True)\n",
        "target_dataloader = DataLoader(art_dataset, batch_size=best_config[\"batch_size\"], shuffle=True, num_workers=4, drop_last=True)\n",
        "test_dataloader = DataLoader(art_dataset, batch_size=best_config[\"batch_size\"], shuffle=False, num_workers=4)\n",
        "\n",
        "net = alexnet(pretrained=True)\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=best_config[\"lr\"], momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=best_config[\"step\"], gamma=GAMMA)\n",
        "\n",
        "net = net.to(DEVICE)\n",
        "\n",
        "cudnn.benchmark \n",
        "\n",
        "current_step = 0\n",
        "loss_list = []\n",
        "test_accuracy_list = []\n",
        "\n",
        "for epoch in range(best_config[\"num_epochs\"]):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, best_config[\"num_epochs\"], scheduler.get_lr()))\n",
        "\n",
        "  # Iterate over the dataset\n",
        "  for images, labels in source_dataloader:\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train() # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Compute loss based on output and ground truth\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "  # Step the scheduler\n",
        "  scheduler.step() \n",
        "\n",
        "  loss_list.append(loss.item())\n",
        "\n",
        "  # Test \n",
        "  net.train(False) # Set Network to evaluation mode\n",
        "  test_running_corrects = 0\n",
        "  for images, labels in test_dataloader:\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    test_outputs = net(images)\n",
        "\n",
        "    # Get predictions\n",
        "    _, test_preds = torch.max(test_outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    test_running_corrects += torch.sum(test_preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  test_accuracy = test_running_corrects / float(len(art_dataset))\n",
        "  print('Test Accuracy {}'.format(test_accuracy))\n",
        "  print()\n",
        "  \n",
        "  test_accuracy_list.append(test_accuracy)\n",
        "\n",
        "print_accuracy_loss_plot(loss_list, test_accuracy_list, \"Best Configuration training without DANN\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/35, LR = [0.01]\n",
            "Step 0, Loss 2.266611099243164\n",
            "Test Accuracy 0.49853515625\n",
            "\n",
            "Starting epoch 2/35, LR = [0.01]\n",
            "Test Accuracy 0.43115234375\n",
            "\n",
            "Starting epoch 3/35, LR = [0.01]\n",
            "Test Accuracy 0.4462890625\n",
            "\n",
            "Starting epoch 4/35, LR = [0.01]\n",
            "Step 10, Loss 0.10215890407562256\n",
            "Test Accuracy 0.478515625\n",
            "\n",
            "Starting epoch 5/35, LR = [0.01]\n",
            "Test Accuracy 0.49169921875\n",
            "\n",
            "Starting epoch 6/35, LR = [0.01]\n",
            "Test Accuracy 0.50390625\n",
            "\n",
            "Starting epoch 7/35, LR = [0.01]\n",
            "Step 20, Loss 0.03217684477567673\n",
            "Test Accuracy 0.49169921875\n",
            "\n",
            "Starting epoch 8/35, LR = [0.01]\n",
            "Test Accuracy 0.45166015625\n",
            "\n",
            "Starting epoch 9/35, LR = [0.01]\n",
            "Test Accuracy 0.43896484375\n",
            "\n",
            "Starting epoch 10/35, LR = [0.01]\n",
            "Test Accuracy 0.44482421875\n",
            "\n",
            "Starting epoch 11/35, LR = [0.01]\n",
            "Step 30, Loss 0.009988056495785713\n",
            "Test Accuracy 0.46435546875\n",
            "\n",
            "Starting epoch 12/35, LR = [0.01]\n",
            "Test Accuracy 0.4794921875\n",
            "\n",
            "Starting epoch 13/35, LR = [0.01]\n",
            "Test Accuracy 0.48095703125\n",
            "\n",
            "Starting epoch 14/35, LR = [0.01]\n",
            "Step 40, Loss 0.0032213376834988594\n",
            "Test Accuracy 0.50146484375\n",
            "\n",
            "Starting epoch 15/35, LR = [0.01]\n",
            "Test Accuracy 0.49755859375\n",
            "\n",
            "Starting epoch 16/35, LR = [0.01]\n",
            "Test Accuracy 0.49072265625\n",
            "\n",
            "Starting epoch 17/35, LR = [0.01]\n",
            "Step 50, Loss 0.002358710393309593\n",
            "Test Accuracy 0.48974609375\n",
            "\n",
            "Starting epoch 18/35, LR = [0.01]\n",
            "Test Accuracy 0.5009765625\n",
            "\n",
            "Starting epoch 19/35, LR = [0.01]\n",
            "Test Accuracy 0.50732421875\n",
            "\n",
            "Starting epoch 20/35, LR = [0.01]\n",
            "Test Accuracy 0.5087890625\n",
            "\n",
            "Starting epoch 21/35, LR = [0.01]\n",
            "Step 60, Loss 0.002379152923822403\n",
            "Test Accuracy 0.5078125\n",
            "\n",
            "Starting epoch 22/35, LR = [0.01]\n",
            "Test Accuracy 0.50390625\n",
            "\n",
            "Starting epoch 23/35, LR = [0.01]\n",
            "Test Accuracy 0.51318359375\n",
            "\n",
            "Starting epoch 24/35, LR = [0.01]\n",
            "Step 70, Loss 0.0005794446915388107\n",
            "Test Accuracy 0.51416015625\n",
            "\n",
            "Starting epoch 25/35, LR = [0.01]\n",
            "Test Accuracy 0.50146484375\n",
            "\n",
            "Starting epoch 26/35, LR = [0.01]\n",
            "Test Accuracy 0.48291015625\n",
            "\n",
            "Starting epoch 27/35, LR = [0.01]\n",
            "Step 80, Loss 0.0020854156464338303\n",
            "Test Accuracy 0.47119140625\n",
            "\n",
            "Starting epoch 28/35, LR = [0.01]\n",
            "Test Accuracy 0.474609375\n",
            "\n",
            "Starting epoch 29/35, LR = [0.01]\n",
            "Test Accuracy 0.48193359375\n",
            "\n",
            "Starting epoch 30/35, LR = [0.01]\n",
            "Test Accuracy 0.48583984375\n",
            "\n",
            "Starting epoch 31/35, LR = [0.0001]\n",
            "Step 90, Loss 0.0008916798979043961\n",
            "Test Accuracy 0.486328125\n",
            "\n",
            "Starting epoch 32/35, LR = [0.001]\n",
            "Test Accuracy 0.486328125\n",
            "\n",
            "Starting epoch 33/35, LR = [0.001]\n",
            "Test Accuracy 0.486328125\n",
            "\n",
            "Starting epoch 34/35, LR = [0.001]\n",
            "Step 100, Loss 0.0002369917929172516\n",
            "Test Accuracy 0.48681640625\n",
            "\n",
            "Starting epoch 35/35, LR = [0.001]\n",
            "Test Accuracy 0.48583984375\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOxZRzFf1uLH",
        "colab_type": "text"
      },
      "source": [
        "**GRID SEARCH Photo to Cartoon and Photo to Sketch with DANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1piPbES1xkQ",
        "colab_type": "code",
        "outputId": "3fdd9ffa-4248-45b9-e6fb-dd3b01d1fa51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hyp_parameters = {\n",
        "  \"batch_size\": [128, 256],\n",
        "  \"lr\": [0.01, 0.001],\n",
        "  \"step\": [20, 30],\n",
        "  \"num_epochs\": [40]\n",
        "  }\n",
        "\n",
        "# with batch_size 512 cuda goes out of memory\n",
        "\n",
        "max_valid_accuracy = 0\n",
        "avg_accuracy = 0\n",
        "best_config = {}\n",
        "number_of_configurations = 2 * 2 * 2\n",
        "alpha = 0.15\n",
        "current_config = 0\n",
        "\n",
        "for config in ParameterGrid(hyp_parameters):\n",
        "  \n",
        "  photo_dataloader = DataLoader(photo_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4, drop_last=True)\n",
        "  cartoon_dataloader = DataLoader(cartoon_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=4)\n",
        "  sketch_dataloader = DataLoader(sketch_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=4)\n",
        "\n",
        "  net = alexnet_with_dann(pretrained=True)\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "  parameters_to_optimize = net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=config['lr'], momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config['step'], gamma=GAMMA)\n",
        "\n",
        "  net = net.to(DEVICE)\n",
        "  cudnn.benchmark \n",
        "\n",
        "  current_step = 0\n",
        "  nan_flag = False\n",
        "  current_config += 1\n",
        "\n",
        "  for epoch in range(config['num_epochs']):\n",
        "    print('Starting epoch {}/{}'.format(epoch+1, config['num_epochs']))\n",
        "\n",
        "    # Iterate over the dataset\n",
        "    train_running_corrects = 0\n",
        "\n",
        "    len_dataloader = min(len(photo_dataloader), len(cartoon_dataloader))\n",
        "    data_source_iter = iter(photo_dataloader)\n",
        "    data_target_iter = iter(cartoon_dataloader)\n",
        "    i = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "\n",
        "      # Dynamic adaptation factor\n",
        "      # p = float(epoch) / NUM_EPOCHS / len_dataloader\n",
        "      # alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "      # print(f\"p = {p}, Alpha = {alpha}\")\n",
        "      # alpha = (1/NUM_EPOCHS) * (epoch)\n",
        "      # print(f\"Alpha = {alpha}\")\n",
        "\n",
        "      # Training on source data\n",
        "      data_source = data_source_iter.next()\n",
        "\n",
        "      images = data_source[0].to(DEVICE)\n",
        "      class_label = data_source[1].to(DEVICE)\n",
        "      domain_label = torch.zeros(config['batch_size'], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "      net.train()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      class_output, domain_output = net(images, alpha)\n",
        "      loss_s_label = criterion(class_output, class_label)\n",
        "      loss_s_domain = criterion(domain_output, domain_label)\n",
        "    \n",
        "      # Training on target data\n",
        "      data_target = data_target_iter.next()\n",
        "    \n",
        "      images = data_target[0].to(DEVICE)\n",
        "      domain_label = torch.ones(config['batch_size'], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "      _, domain_output = net(images, alpha)\n",
        "      loss_t_domain = criterion(domain_output, domain_label)\n",
        "      loss = loss_t_domain + loss_s_domain + loss_s_label\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      i += 1\n",
        "\n",
        "      # Log loss\n",
        "      # if current_step % LOG_FREQUENCY == 0:\n",
        "      #   print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "      current_step += 1\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Cartoon Validation\n",
        "    net.train(False)\n",
        "    cartoon_running_corrects = 0\n",
        "    for images, labels in cartoon_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      cartoon_outputs, _ = net(images, alpha)\n",
        "\n",
        "      # Get predictions\n",
        "      _, cartoon_preds = torch.max(cartoon_outputs.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      cartoon_running_corrects += torch.sum(cartoon_preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    cartoon_accuracy = cartoon_running_corrects / float(len(art_dataset))\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "\n",
        "    # Iterate over the dataset\n",
        "    train_running_corrects = 0\n",
        "\n",
        "    len_dataloader = min(len(photo_dataloader), len(sketch_dataloader))\n",
        "    data_source_iter = iter(photo_dataloader)\n",
        "    data_target_iter = iter(sketch_dataloader)\n",
        "    i = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "\n",
        "      # Dynamic adaptation factor\n",
        "      # p = float(epoch) / NUM_EPOCHS / len_dataloader\n",
        "      # alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "      # print(f\"p = {p}, Alpha = {alpha}\")\n",
        "      # alpha = (1/NUM_EPOCHS) * (epoch)\n",
        "      # print(f\"Alpha = {alpha}\")\n",
        "\n",
        "      # Training on source data\n",
        "      data_source = data_source_iter.next()\n",
        "\n",
        "      images = data_source[0].to(DEVICE)\n",
        "      class_label = data_source[1].to(DEVICE)\n",
        "      domain_label = torch.zeros(config['batch_size'], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "      net.train()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      class_output, domain_output = net(images, alpha)\n",
        "      loss_s_label = criterion(class_output, class_label)\n",
        "      loss_s_domain = criterion(domain_output, domain_label)\n",
        "    \n",
        "      # Training on target data\n",
        "      data_target = data_target_iter.next()\n",
        "    \n",
        "      images = data_target[0].to(DEVICE)\n",
        "      domain_label = torch.ones(config['batch_size'], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "      _, domain_output = net(images, alpha)\n",
        "      loss_t_domain = criterion(domain_output, domain_label)\n",
        "      loss = loss_t_domain + loss_s_domain + loss_s_label\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      i += 1\n",
        "\n",
        "      # Log loss\n",
        "      # if current_step % LOG_FREQUENCY == 0:\n",
        "      #   print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "      current_step += 1\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Sketch Validation \n",
        "    net.train(False)\n",
        "    sketch_running_corrects = 0\n",
        "    for images, labels in sketch_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      sketch_outputs, _ = net(images, alpha)\n",
        "\n",
        "      # Get predictions\n",
        "      _, sketch_preds = torch.max(sketch_outputs.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      sketch_running_corrects += torch.sum(sketch_preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    sketch_accuracy = sketch_running_corrects / float(len(art_dataset))\n",
        "    \n",
        "    # Best Configuration -------------------------------------------------------\n",
        "    avg_accuracy = (sketch_accuracy + cartoon_accuracy) / 2\n",
        "    if avg_accuracy > max_valid_accuracy:\n",
        "      max_valid_accuracy = avg_accuracy\n",
        "      best_config = config\n",
        "\n",
        "  print(avg_accuracy, config)\n",
        "\n",
        "print(f\"Max Accuracy = {max_valid_accuracy}\")\n",
        "print(f\"Achieved with configuration: {best_config}\")\n",
        "\n",
        "# Max Accuracy = \n",
        "# Achieved with configuration: {'batch_size': 512, 'lr': 0.01, 'num_epochs': 35, 'step': 30}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.283447265625 {'batch_size': 128, 'lr': 0.01, 'num_epochs': 40, 'step': 20}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.283447265625 {'batch_size': 128, 'lr': 0.01, 'num_epochs': 40, 'step': 30}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.779296875 {'batch_size': 128, 'lr': 0.001, 'num_epochs': 40, 'step': 20}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.831298828125 {'batch_size': 128, 'lr': 0.001, 'num_epochs': 40, 'step': 30}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.283447265625 {'batch_size': 256, 'lr': 0.01, 'num_epochs': 40, 'step': 20}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.283447265625 {'batch_size': 256, 'lr': 0.01, 'num_epochs': 40, 'step': 30}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.3720703125 {'batch_size': 256, 'lr': 0.001, 'num_epochs': 40, 'step': 20}\n",
            "Starting epoch 1/40\n",
            "Starting epoch 2/40\n",
            "Starting epoch 3/40\n",
            "Starting epoch 4/40\n",
            "Starting epoch 5/40\n",
            "Starting epoch 6/40\n",
            "Starting epoch 7/40\n",
            "Starting epoch 8/40\n",
            "Starting epoch 9/40\n",
            "Starting epoch 10/40\n",
            "Starting epoch 11/40\n",
            "Starting epoch 12/40\n",
            "Starting epoch 13/40\n",
            "Starting epoch 14/40\n",
            "Starting epoch 15/40\n",
            "Starting epoch 16/40\n",
            "Starting epoch 17/40\n",
            "Starting epoch 18/40\n",
            "Starting epoch 19/40\n",
            "Starting epoch 20/40\n",
            "Starting epoch 21/40\n",
            "Starting epoch 22/40\n",
            "Starting epoch 23/40\n",
            "Starting epoch 24/40\n",
            "Starting epoch 25/40\n",
            "Starting epoch 26/40\n",
            "Starting epoch 27/40\n",
            "Starting epoch 28/40\n",
            "Starting epoch 29/40\n",
            "Starting epoch 30/40\n",
            "Starting epoch 31/40\n",
            "Starting epoch 32/40\n",
            "Starting epoch 33/40\n",
            "Starting epoch 34/40\n",
            "Starting epoch 35/40\n",
            "Starting epoch 36/40\n",
            "Starting epoch 37/40\n",
            "Starting epoch 38/40\n",
            "Starting epoch 39/40\n",
            "Starting epoch 40/40\n",
            "0.35302734375 {'batch_size': 256, 'lr': 0.001, 'num_epochs': 40, 'step': 30}\n",
            "Max Accuracy = 0.841796875\n",
            "Achieved with configuration: {'batch_size': 128, 'lr': 0.001, 'num_epochs': 40, 'step': 30}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9LtMuR10wd",
        "colab_type": "text"
      },
      "source": [
        "**3B with best config**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwON3YKz11Il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To avoid re-run of previous code cell\n",
        "# Max Accuracy = 0.7275390625\n",
        "best_config = {'batch_size': 128, 'lr': 0.001, 'num_epochs': 35, 'step': 30}\n",
        "\n",
        "source_dataloader = DataLoader(photo_dataset, batch_size=best_config[\"batch_size\"], shuffle=True, num_workers=4, drop_last=True)\n",
        "target_dataloader = DataLoader(art_dataset, batch_size=best_config[\"batch_size\"], shuffle=True, num_workers=4, drop_last=True)\n",
        "test_dataloader = DataLoader(art_dataset, batch_size=best_config[\"batch_size\"], shuffle=False, num_workers=4)\n",
        "\n",
        "net = alexnet_with_dann(pretrained=True)\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=best_config[\"lr\"], momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=best_config[\"step\"], gamma=GAMMA)\n",
        "\n",
        "net = net.to(DEVICE)\n",
        "cudnn.benchmark\n",
        "\n",
        "current_step = 0\n",
        "loss_list1 = []\n",
        "loss_list2 = []\n",
        "loss_list3 = []\n",
        "loss_list4 = []\n",
        "test_accuracy_list = []\n",
        "\n",
        "# Static adaptation factor\n",
        "alpha = 0.2\n",
        "\n",
        "# Start iterating over the epochs\n",
        "for epoch in range(best_config[\"num_epochs\"]):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, best_config[\"num_epochs\"], scheduler.get_lr()))\n",
        "\n",
        "  # Iterate over the dataset\n",
        "  train_running_corrects = 0\n",
        "\n",
        "  len_dataloader = min(len(source_dataloader), len(target_dataloader))\n",
        "  data_source_iter = iter(source_dataloader)\n",
        "  data_target_iter = iter(target_dataloader)\n",
        "  i = 0\n",
        "\n",
        "  while i < len_dataloader:\n",
        "\n",
        "    loss2 = 0\n",
        "    loss3 = 0\n",
        "    loss4 = 0\n",
        "    cnt = 0\n",
        "\n",
        "    # Dynamic adaptation factor\n",
        "    # p = float(epoch) / NUM_EPOCHS / len_dataloader\n",
        "    # alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "    # print(f\"p = {p}, Alpha = {alpha}\")\n",
        "    # alpha = (1/NUM_EPOCHS) * (epoch)\n",
        "    # print(f\"Alpha = {alpha}\")\n",
        "\n",
        "    # Training on source data\n",
        "    data_source = data_source_iter.next()\n",
        "\n",
        "    images = data_source[0].to(DEVICE)\n",
        "    class_label = data_source[1].to(DEVICE)\n",
        "    domain_label = torch.zeros(best_config[\"batch_size\"], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "    net.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    class_output, domain_output = net(images, alpha)\n",
        "    loss_s_label = criterion(class_output, class_label)\n",
        "    loss_s_domain = criterion(domain_output, domain_label)\n",
        "\n",
        "    loss2 = loss2 + loss_s_label.item()\n",
        "    loss3 = loss3 + loss_s_domain.item()\n",
        "    \n",
        "    # Training on target data\n",
        "    data_target = data_target_iter.next()\n",
        "    \n",
        "    images = data_target[0].to(DEVICE)\n",
        "    domain_label = torch.ones(best_config[\"batch_size\"], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "    _, domain_output = net(images, alpha)\n",
        "    loss_t_domain = criterion(domain_output, domain_label)\n",
        "\n",
        "    loss4 = loss4 + loss_t_domain.item()\n",
        "\n",
        "    loss = loss_t_domain + loss_s_domain + loss_s_label\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    i += 1\n",
        "\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, loss_s_label.item()))\n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "  # Step the scheduler\n",
        "  scheduler.step()\n",
        "\n",
        "  cnt += 1\n",
        "  loss_list1.append(loss_s_label.item())\n",
        "  loss_list2.append(loss2/cnt)\n",
        "  loss_list3.append(loss3/cnt)\n",
        "  loss_list4.append(loss4/cnt)\n",
        "\n",
        "  # Test \n",
        "  net.train(False)\n",
        "  test_running_corrects = 0\n",
        "  for images, labels in test_dataloader:\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    test_outputs, _ = net(images, alpha)\n",
        "\n",
        "    # Get predictions\n",
        "    _, test_preds = torch.max(test_outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    test_running_corrects += torch.sum(test_preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  test_accuracy = test_running_corrects / float(len(art_dataset))\n",
        "  print('Test Accuracy {}'.format(test_accuracy))\n",
        "  print()\n",
        "\n",
        "  test_accuracy_list.append(test_accuracy)\n",
        "\n",
        "print_accuracy_loss_plot(loss_list1, test_accuracy_list, \"Best Configuration training with DANN\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nh-HV9B2wzt",
        "colab_type": "text"
      },
      "source": [
        "**Losses plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A49Ad8tMW--M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "ax.plot(loss_list2, c='blue', label='Source Classifier Loss')\n",
        "ax.plot(loss_list3, c='orange', label='Source Domain Loss')\n",
        "ax.plot(loss_list4, c='red', label='Target Domain Loss')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Loss')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.savefig(\"loss_plot.png\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}